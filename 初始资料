三个方面 
一、减少代码量
二、从硬件上来说
三、设置参数
(开启动态分区) set hive.exec.dynamic.partition.mode=nonstrict;
(每个节点生成的动态分区的最大个数 默认100 ) set hive.exec.max.dynamic.partitions.pernode=10000;


(一个DML操作可以创建的最大动态分区数，默认是1000) set hive.exec.max.dynamic.partitions=100000;


如果内存溢出：
(减少set mapred.max.split.size的值,增加map的数量，增加map内存) set mapred.max.split.size=25600000;
(设置map内存) set mapreduce.map.memory.mb=8192   默认1024;
(设置reduce内存) set mapreduce.redyce.memory.mb=8192;
(设置堆内存) mapred.child.java.opts=-Xmx6144m;map%75
(设置并行执行) set hive.exec.parallel=true;
(设置中间结果压缩) set mapred.map.output.compression.codec=org.apache.Hadoop.io.compress.SnappyCodec;
(如果发生数据倾斜，可以尝试设置此参数) hive.groupby.skewindata = true;数据倾斜先聚合一下然后再处理
hive.merge.mapfiles; //设置map读取数据是合并小文件
hive.exec.parallel; //任务并行执行
hive.exec.reducers.bytes.per.reducer //多少个字节的数据产生一个reduce
hive.exec.reducers.max //reduce的最大个数
hive.exec.default.partition.name //hive默认分区名字,碰到值为空或者null,数据就到默认分区
hive.exec.mode.local.auto //决定Hive是否应该自动地根据输入文件大小，在本地运行
hive.auto.convert.join //开关map join模式
hive.groupby.skewindata //数据倾斜
